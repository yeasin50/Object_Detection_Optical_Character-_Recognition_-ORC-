{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  <div style=\"text-align: center\">The Sparks Foundations IoT & Computer Vision intern </div>\n",
    "<br>\n",
    "<font size=4>Task 1: Character detector  </font>  <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=4>\n",
    "By: Md. Yeasin Sheikh</font> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3.4>In this section we will look an overview of how we can use openCv and Tesseract to extract data/Text from image. It can be applied to hand-Writing images and video.\n",
    "\n",
    "‚ö† Make sure you have Tesseract on your system. else follow README.md file. </font>\n",
    "\n",
    "<font  size=4.5> Let's see how its woks </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages we need\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "import cv2\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>locate the path of tesseract.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'I:\\ML_Install\\tesseract\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Characters\n",
    "openCV use BGR image but pytesseract need RGB image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'assets/slide1.png') # getting image from directory\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # conveting into RGB image\n",
    "\n",
    "rectColor = (28,255,1) \n",
    "fontColor = (255,0,164)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL \n",
    "imgHeight, imgWidth,_ = img.shape\n",
    "\n",
    "boxes = pytesseract.image_to_boxes(img_rgb) # it helps to get the character's positions\n",
    "\n",
    "for b in boxes.splitlines():\n",
    "    # print(b)\n",
    "    b = b.split(' ')\n",
    "    x, y, w, h=  int(b[1]),int(b[2]),int(b[3]), int(b[4])\n",
    "    cv2.rectangle(img, (x, imgHeight-y), (w, imgHeight- h), rectColor, 1)\n",
    "    cv2.putText(img, b[0],(x,imgHeight-y+20),font,1, fontColor )\n",
    "\n",
    "cv2.imshow(\"Detect Every Character\", img)\n",
    "cv2.waitKey(0) # wait until we press 'q' or close the popUp window\n",
    "cv2.destroyAllWindows() # clear previous windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Words\n",
    "to get word we need to use <font color='blue'>ytesseract.image_to_data()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from Image:\n",
      "¬Æ Secret Summaries\n",
      "\n",
      "+ When you want to attract a relationship, make sure your thoughts, words,\n",
      "actions, and surroundings don‚Äôt contradict your desires.\n",
      "\n",
      "+ Your job is you. Unless you fill yourself up first, you have nothing to give\n",
      "anybody.\n",
      "\n",
      "+ Treat yourself with love and respect, and you will attract people who show\n",
      "you love and respect.\n",
      "\n",
      "+ When you feel bad about yourself, you block the love and instead you attract\n",
      "more people and situations that will continue to make you feel bad about you.\n",
      "\n",
      "+ Focus on the qualities you love about yourself and the law of attraction will\n",
      "show you more great things about you.\n",
      "\n",
      "+ To make a relationship work, focus on what you appreciate about the other\n",
      "person, and not your complaints. When you focus on the strengths, you will get\n",
      "more of them.\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(r'assets/ocr2.png')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "rectColor = (28,255,1)\n",
    "fontColor = (255,0,164)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "imgHeight, imgWidth,_ = img.shape\n",
    "\n",
    "text = pytesseract.image_to_string(image=img_rgb, config='--psm 6') # return texts from image\n",
    "print(\"Text from Image:\\n\"+text)\n",
    "boxes = pytesseract.image_to_data(img_rgb) \n",
    "\n",
    "for x, b in enumerate(boxes.splitlines()):\n",
    "    if(x!=0):\n",
    "        b = b.split()\n",
    "#         print(b)\n",
    "        if len(b)==12: # proper output return 12 column\n",
    "            x, y, w, h= int(b[6]),int(b[7]),int(b[8]), int(b[9])\n",
    "            cv2.rectangle(img, (x,y), (w+x, h+y), rectColor, 1)\n",
    "            cv2.putText(img, b[11],(x,y), font, .01, fontColor, 1)\n",
    "    \n",
    "cv2.imshow(\"Image from PDF-'The Secret'\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() # clear previous windows  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Digits\n",
    "This <font size=3.5 color='green'> 'outputbase digits'</font> parameter return only digits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'assets/digit.png')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "conf = r'--oem 3 --psm 6 outputbase digits'\n",
    "\n",
    "rectColor = (28,255,1)\n",
    "fontColor = (255,0,164)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL \n",
    "imgHeight, imgWidth,_ = img.shape\n",
    "\n",
    "boxes = pytesseract.image_to_boxes(img_rgb, config= conf)\n",
    "\n",
    "for b in boxes.splitlines():\n",
    "    # print(b)\n",
    "    b = b.split(' ')\n",
    "    x, y, w, h=  int(b[1]),int(b[2]),int(b[3]), int(b[4])\n",
    "    cv2.rectangle(img, (x, imgHeight-y), (w, imgHeight- h), rectColor, 1)\n",
    "    cv2.putText(img, b[0],(x,imgHeight-y+20),font,1, fontColor )\n",
    "cv2.imshow(\"Detect Every Digit\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Bengali word detection\n",
    "\n",
    "<font size=3.5>By default pytesseract use English, we have to use <font color='blue'>lang</font> parameter for differents language. </font>  \n",
    "According to this opencv forum, putText is only able to support a small ascii subset of characters and does not support unicode characters which are other symboles like chinese and arabic characters. \n",
    "However, you can try to use PIL instead üòÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡¶ö‡¶ø‡¶∞‡¶ï‡¶æ‡¶≤ ‡¶Ö‡¶®‡ßç‡¶ß‡¶ï‡¶æ‡¶∞‡¶ï‡ßá\n",
      "\n",
      "‡¶ó‡¶æ‡¶≤‡¶Æ‡¶®‡ßç‡¶¶ ‡¶®‡¶æ ‡¶ï‡¶∞‡ßá ‡¶õ‡ßã‡¶ï‡ßç‡¶ü\n",
      "\n",
      "‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡¶æ‡¶§‡¶ø ‡¶ú‡ßç‡¶¨‡¶æ‡¶≤‡¶æ‡¶®‡ßã\n",
      "‡¶Ö‡¶®‡ßá‡¶ï ‡¶≠‡¶æ‡¶≤‡•§\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(r'assets/bnQoute.jpg')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "rectColor = (28,255,1)\n",
    "fontColor = (255,0,164)\n",
    "imgHeight, imgWidth,_ = img.shape\n",
    "\n",
    "conf = r'--oem 3 --psm 6'\n",
    "langs = 'ben'\n",
    "\n",
    "text = pytesseract.image_to_string(image=img_rgb, lang=langs, config= conf)\n",
    "print(text)\n",
    "boxes = pytesseract.image_to_data(img_rgb, lang=langs, config=conf)\n",
    "\n",
    "for x, b in enumerate(boxes.splitlines()):\n",
    "    if(x!=0):\n",
    "        b = b.split()\n",
    "#         print(b)\n",
    "        if len(b)==12: # proper output return 12 column\n",
    "            x, y, w, h= int(b[6]),int(b[7]),int(b[8]), int(b[9])\n",
    "            cv2.rectangle(img, (x,y), (w+x, h+y), rectColor, 1)\n",
    "            \n",
    "cv2.imshow(\"Bengal \", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() # clear previous windows  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Language word detecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3.5>By default pytesseract use English, we have to pass value through <font color='blue'>lang</font> parameter for differents language. Also there could be some collision while mixing multiple languages.</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"‡¶ö‡¶ø‡¶∞‡¶ï‡¶æ‡¶≤ ‡¶Ö‡¶®‡ßç‡¶ß‡¶ï‡¶æ‡¶∞‡¶ï‡ßá\n",
      "‡¶ó‡¶æ‡¶≤‡¶Æ‡¶®‡ßç‡¶¶ ‡¶®‡¶æ‡¶ï‡¶∞‡ßá CAG\n",
      "‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡¶æ‡¶§‡¶ø ‡¶ú‡ßç‡¶¨‡¶æ‡¶≤‡¶æ‡¶®‡ßã\n",
      "‡¶Ö‡¶®‡ßá‡¶ï ‡¶≠‡¶æ‡¶≤‡•§ \"\n",
      "The beauty you see in me is a\n",
      "reflection of you. - Rumi\n",
      "‚ÄèŸÜÿØ€å ⁄©€å ÿ¢ŸÜ⁄©⁄æŸà⁄∫ ⁄©€í ŸÜ€å⁄Ü€í ⁄Ü⁄æŸæ€å €Å€í‚Äé ‡ß¶‡ß¶‡ß¨‡ß¶\n",
      "‚Äè..ÿ®ÿßÿØŸÑ ÿ≥€í ÿß€å⁄© ÿ®⁄ë€å ÿßŸÖ€åÿØ €Å€í‚Äé\n",
      "-Nihal Shaik\n",
      "‡§§‡•Ç‡§´‡§æ‡§®‡•ã‡§Ç ‡§∏‡•á ‡§Ü‡§Å‡§ñ ‡§Æ‡§ø‡§≤‡§æ‡§ì ,‡§∏‡•à‡§≤‡§æ‡§¨‡•ã‡§Ç ‡§™‡§∞ ‡¶®‡¶æ‡¶Ç ‡§ï‡§∞‡•ã,\n",
      "‡§Æ‡§≤‡•ç‡§≤‡§æ‡§π‡•ã‡§Ç ‡§ï‡§æ ‡§ö‡§ï‡•ç‡§ï‡§∞ ‡§õ‡•ã‡§°‡§º‡•ã, ALS ‡§¶‡§∞‡§ø‡§Ø‡§æ ‡§™‡§æ‡§∞ ‡§ï‡§∞‡•ã\n",
      "- ‡§∞‡§æ‡§π‡§§ ‡§á‡§®‡•ç‡§¶‡•ã‡§∞‡•Ä\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(r'assets/multilan.png')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "rectColor = (28,255,1)\n",
    "fontColor = (255,0,164)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "imgHeight, imgWidth,_ = img.shape\n",
    "\n",
    "conf = r'--oem 3 --psm 6'\n",
    "langs = 'ben+urd+eng+hin'\n",
    "\n",
    "text = pytesseract.image_to_string(image=img_rgb, lang=langs, config= conf)\n",
    "print(text)\n",
    "boxes = pytesseract.image_to_data(img_rgb, lang=langs, config=conf)\n",
    "\n",
    "for x, b in enumerate(boxes.splitlines()):\n",
    "    if(x!=0):\n",
    "        b = b.split()\n",
    "#         print(b)\n",
    "        if len(b)==12: # proper output return 12 column\n",
    "            x, y, w, h= int(b[6]),int(b[7]),int(b[8]), int(b[9])\n",
    "            cv2.rectangle(img, (x,y), (w+x, h+y), rectColor, 1)\n",
    "            \n",
    "            \n",
    "cv2.imshow(\"Multi-Language \", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() # clear previous windows  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
